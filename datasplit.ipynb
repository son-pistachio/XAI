{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 43664\n",
      "Validation set size: 10916\n",
      "Test set size: 54581\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# MLRSNet 데이터셋의 루트 디렉토리 설정\n",
    "mlrsnet_root = '/home/son/ml/datasets/MLRSNet'  # MLRSNet 데이터셋의 최상위 폴더 경로로 변경하세요\n",
    "\n",
    "# 레이블 디렉토리 경로 설정\n",
    "labels_dir = os.path.join(mlrsnet_root, 'Labels')\n",
    "\n",
    "# 모든 레이블 CSV 파일 불러오기\n",
    "label_files = glob.glob(os.path.join(labels_dir, '*.csv'))\n",
    "\n",
    "# 모든 레이블 데이터를 하나의 데이터프레임으로 합치기\n",
    "all_labels_df = pd.DataFrame()\n",
    "\n",
    "for file in label_files:\n",
    "    df = pd.read_csv(file)\n",
    "    # 이미지 경로 수정: 이미지 파일명이 있는 폴더명을 추출하여 경로 생성\n",
    "    class_name = os.path.splitext(os.path.basename(file))[0]  # 파일명에서 클래스명 추출\n",
    "    # 이미지 경로 생성\n",
    "    df['image'] = df['image'].apply(lambda x: os.path.join('Images', class_name, x))\n",
    "    all_labels_df = pd.concat([all_labels_df, df], ignore_index=True)\n",
    "\n",
    "# 이미지 경로에 MLRSNet 루트 경로를 추가\n",
    "all_labels_df['image'] = all_labels_df['image'].apply(lambda x: os.path.join(mlrsnet_root, x))\n",
    "\n",
    "# 데이터 섞기\n",
    "all_labels_df = all_labels_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 데이터 분할 비율 설정 (예: 70% train, 15% val, 15% test)\n",
    "train_ratio = 0.4\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.5\n",
    "\n",
    "# 먼저 train과 나머지(val+test)를 분할\n",
    "train_df, temp_df = train_test_split(all_labels_df, test_size=(1 - train_ratio), random_state=42)\n",
    "\n",
    "# 남은 데이터(temp_df)를 val과 test로 분할\n",
    "val_df, test_df = train_test_split(temp_df, test_size=(test_ratio / (test_ratio + val_ratio)), random_state=42)\n",
    "\n",
    "# 각 분할의 데이터 수 확인\n",
    "print(f\"Train set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "\n",
    "# CSV 파일 저장 경로 설정\n",
    "output_dir = '/home/son/ml/xai_new/split_data_v2'  # 현재 작업 디렉토리로 설정하거나 원하는 경로로 변경하세요\n",
    "\n",
    "# CSV 파일로 저장\n",
    "train_df.to_csv(os.path.join(output_dir, 'train.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(output_dir, 'val.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(output_dir, 'test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
