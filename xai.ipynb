{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import yaml\n",
    "import pytorch_lightning as pl\n",
    "from densenet201 import DenseNetModel\n",
    "%matplotlib inline\n",
    "\n",
    "# 랜덤 시드 고정 함수\n",
    "def set_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)  # 랜덤 시드 통합\n",
    "\n",
    "# 모델, 디바이스, 이미지 변환 함수\n",
    "def prepare_model_and_transform(model, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return model, transform\n",
    "\n",
    "# 이미지 시각화 함수\n",
    "def display_image(image, title=''):\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Grad-CAM 적용 함수\n",
    "# def apply_grad_cam(model, image_path, model_name):\n",
    "#     device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#     model, transform = prepare_model_and_transform(model, device)\n",
    "\n",
    "#     img = Image.open(image_path).convert('RGB')\n",
    "#     img_resized = img.resize((256, 256))\n",
    "#     img_tensor = transform(img_resized).unsqueeze(0).to(device)\n",
    "    \n",
    "#     target_layer = get_target_layer(model, model_name)\n",
    "#     cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "#     grayscale_cam = cam(input_tensor=img_tensor)[0, :]\n",
    "    \n",
    "#     img_np = np.array(img_resized) / 255.0\n",
    "#     visualization = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)\n",
    "    \n",
    "#     display_image(visualization, 'Grad-CAM')\n",
    "\n",
    "#     return grayscale_cam  # 반환된 CAM을 insertion, deletion에서 사용\n",
    "\n",
    "# Grad-CAM 마스크 시각화 확인\n",
    "def apply_grad_cam(model, image_path, model_name):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model, transform = prepare_model_and_transform(model, device)\n",
    "\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_resized = img.resize((256, 256))\n",
    "    img_tensor = transform(img_resized).unsqueeze(0).to(device)\n",
    "    \n",
    "    target_layer = get_target_layer(model, model_name)\n",
    "    cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "    grayscale_cam = cam(input_tensor=img_tensor)[0, :]\n",
    "    \n",
    "    img_np = np.array(img_resized) / 255.0\n",
    "    visualization = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)\n",
    "    \n",
    "    display_image(visualization, 'Grad-CAM')\n",
    "    \n",
    "    # CAM 마스크 시각화\n",
    "    plt.imshow(grayscale_cam, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Grad-CAM Mask\")\n",
    "    plt.show()\n",
    "\n",
    "    return grayscale_cam  # 반환된 CAM을 insertion, deletion에서 사용\n",
    "\n",
    "\n",
    "# LIME을 위한 batch_predict 함수\n",
    "def batch_predict(model, images, transform, device):\n",
    "    batch = torch.stack([transform(Image.fromarray(image)) for image in images], dim=0).to(device)\n",
    "    logits = model(batch)\n",
    "    return torch.softmax(logits, dim=1).detach().cpu().numpy()\n",
    "\n",
    "# LIME 적용 함수\n",
    "def apply_lime(model, image_path):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model, transform = prepare_model_and_transform(model, device)\n",
    "\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_resized = img.resize((256, 256))\n",
    "    img_tensor = transform(img_resized).unsqueeze(0).to(device)\n",
    "\n",
    "    outputs = model(img_tensor)\n",
    "    probs = torch.softmax(outputs, dim=1).detach().cpu().numpy()[0]\n",
    "    class_idx = np.argmax(probs)\n",
    "    \n",
    "    explainer = lime_image.LimeImageExplainer(random_state=42)\n",
    "    explanation = explainer.explain_instance(np.array(img_resized), lambda x: batch_predict(model, x, transform, device), labels=[class_idx], num_samples=1000)\n",
    "    \n",
    "    temp, mask = explanation.get_image_and_mask(label=class_idx, positive_only=True, num_features=5, hide_rest=False)\n",
    "    img_boundaries = mark_boundaries(temp / 255.0, mask)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(img_boundaries)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('LIME')\n",
    "    \n",
    "    white_image = np.ones_like(temp) * 255\n",
    "    only_important = np.copy(white_image)\n",
    "    only_important[mask != 0] = temp[mask != 0]\n",
    "    \n",
    "    ax[1].imshow(only_important.astype(np.uint8))\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('Important Areas Only')\n",
    "    plt.show()\n",
    "\n",
    "# Insertion/Deletion 시각화 함수\n",
    "def insertion_deletion(model, img_tensor, mask, mode='insertion', steps=20, class_idx=0):\n",
    "    device = img_tensor.device\n",
    "    img_tensor = img_tensor.clone().detach().to(device)\n",
    "    \n",
    "    scores = []\n",
    "    images = []\n",
    "    step = 1.0 / steps\n",
    "    for i in range(steps + 1):\n",
    "        if mode == 'insertion':\n",
    "            modified_img = img_tensor * (1 - mask * (step * i)).to(device)\n",
    "        elif mode == 'deletion':\n",
    "            modified_img = img_tensor * (mask * (step * i)).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = torch.softmax(model(modified_img), dim=1)[:, class_idx].cpu().item()\n",
    "        scores.append(output)\n",
    "        images.append(modified_img.cpu().squeeze().permute(1, 2, 0).numpy())  # 이미지 저장\n",
    "\n",
    "    return scores, images\n",
    "\n",
    "# 이미지 정규화 함수\n",
    "def normalize_image(img):\n",
    "    img_min, img_max = img.min(), img.max()\n",
    "    if img_min == img_max:\n",
    "        return img  # 모든 값이 동일하면 정규화 불필요\n",
    "    return (img - img_min) / (img_max - img_min)\n",
    "\n",
    "# Insertion/Deletion 스텝별 시각화 함수\n",
    "def visualize_insertion_deletion_steps(images, mode, steps=20):\n",
    "    fig, axs = plt.subplots(2, (steps // 2) + 1, figsize=(20, 5))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        img = normalize_image(img)\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(f\"{mode.capitalize()} Step {i}\")\n",
    "    \n",
    "    # 남은 빈 플롯들 숨기기\n",
    "    for j in range(len(images), len(axs)):\n",
    "        axs[j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Insertion 및 Deletion 수행 및 시각화 함수\n",
    "def apply_insertion_deletion_visualize(model, image_path, cam_mask=None, steps=20, mode='gradcam'):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model, transform = prepare_model_and_transform(model, device)\n",
    "\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_resized = img.resize((256, 256))\n",
    "    img_tensor = transform(img_resized).unsqueeze(0).to(device)\n",
    "\n",
    "    outputs = model(img_tensor)\n",
    "    probs = torch.softmax(outputs, dim=1).detach().cpu().numpy()[0]\n",
    "    class_idx = np.argmax(probs)\n",
    "\n",
    "    if mode == 'lime':\n",
    "        explainer = lime_image.LimeImageExplainer(random_state=42)\n",
    "        explanation = explainer.explain_instance(np.array(img_resized), lambda x: batch_predict(model, x, transform, device), labels=[class_idx], num_samples=1000)\n",
    "        _, mask = explanation.get_image_and_mask(label=class_idx, positive_only=True, num_features=5, hide_rest=False)\n",
    "        mask = torch.tensor(mask).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "    else:\n",
    "        mask = torch.tensor(cam_mask).unsqueeze(0).unsqueeze(0).float().to(device)  # Grad-CAM 마스크 사용\n",
    "\n",
    "    # Insertion\n",
    "    insertion_scores, insertion_images = insertion_deletion(model, img_tensor, mask, mode='insertion', steps=steps, class_idx=class_idx)\n",
    "    \n",
    "    # Deletion\n",
    "    deletion_scores, deletion_images = insertion_deletion(model, img_tensor, mask, mode='deletion', steps=steps, class_idx=class_idx)\n",
    "\n",
    "    # 결과 곡선 시각화\n",
    "    plt.plot(np.linspace(0, 1, steps + 1), insertion_scores, label='Insertion')\n",
    "    plt.plot(np.linspace(0, 1, steps + 1), deletion_scores, label='Deletion')\n",
    "    plt.xlabel('Percentage of Important Region')\n",
    "    plt.ylabel('Model Output Score')\n",
    "    plt.title(f'Insertion and Deletion Curves ({mode.capitalize()})')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 스텝별 이미지 시각화\n",
    "    visualize_insertion_deletion_steps(insertion_images, mode='insertion', steps=steps)\n",
    "    visualize_insertion_deletion_steps(deletion_images, mode='deletion', steps=steps)\n",
    "\n",
    "# 실행 예시\n",
    "model_name = 'densenet'\n",
    "image_path = '/home/xai/son/MLRSNet/Images/parking_lot/parking_lot_00004.jpg'\n",
    "\n",
    "# 모델 로드\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "model = DenseNetModel.load_from_checkpoint(\n",
    "    checkpoint_path='/home/xai/son/src/checkpoints/densnet201/densnet201-val_loss=0.10-val_f1=0.78.ckpt',\n",
    "    num_classes=config['data']['num_classes'],\n",
    "    learning_rate=config['train']['learning_rate']\n",
    ")\n",
    "\n",
    "# Grad-CAM 수행\n",
    "cam_mask = apply_grad_cam(model, image_path, model_name)\n",
    "\n",
    "# Insertion 및 Deletion 수행 및 시각화 (Grad-CAM 기반)\n",
    "apply_insertion_deletion_visualize(model, image_path, cam_mask=cam_mask, steps=10, mode='gradcam')\n",
    "\n",
    "# Insertion 및 Deletion 수행 및 시각화 (LIME 기반)\n",
    "apply_insertion_deletion_visualize(model, image_path, steps=10, mode='lime')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
