{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import yaml\n",
    "import pytorch_lightning as pl\n",
    "from densenet201 import DenseNetModel\n",
    "from numpy import trapz\n",
    "%matplotlib inline\n",
    "\n",
    "# 랜덤 시드 고정 함수\n",
    "def set_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)  # 랜덤 시드 통합\n",
    "# XAI 관련 함수 정의\n",
    "def get_target_layer(model, model_name):\n",
    "    if model_name == 'resnet':\n",
    "        return model.model.layer4[-1]\n",
    "    elif model_name == 'googlenet':\n",
    "        return model.model.inception5b\n",
    "    elif model_name == 'efficientnet':\n",
    "        return model.model.features[-1]\n",
    "    elif model_name == 'densenet':\n",
    "        return model.model.features[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "# 모델, 디바이스, 이미지 변환 함수\n",
    "def prepare_model_and_transform(model, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return model, transform\n",
    "\n",
    "# 이미지 시각화 함수\n",
    "def display_image(image, title=''):\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Grad-CAM 마스크 시각화 확인\n",
    "def apply_grad_cam(model, image_path, model_name):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model, transform = prepare_model_and_transform(model, device)\n",
    "\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_resized = img.resize((256, 256))\n",
    "    img_tensor = transform(img_resized).unsqueeze(0).to(device)\n",
    "    \n",
    "    target_layer = get_target_layer(model, model_name)\n",
    "    cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "    grayscale_cam = cam(input_tensor=img_tensor)[0, :]\n",
    "    \n",
    "    img_np = np.array(img_resized) / 255.0\n",
    "    visualization = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)\n",
    "    \n",
    "    display_image(visualization, 'Grad-CAM')\n",
    "    \n",
    "    # CAM 마스크 시각화\n",
    "    plt.imshow(grayscale_cam, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Grad-CAM Mask\")\n",
    "    plt.show()\n",
    "\n",
    "    return grayscale_cam\n",
    "\n",
    "\n",
    "# LIME을 위한 batch_predict 함수\n",
    "def batch_predict(model, images, transform, device):\n",
    "    batch = torch.stack([transform(Image.fromarray(image)) for image in images], dim=0).to(device)\n",
    "    logits = model(batch)\n",
    "    return torch.softmax(logits, dim=1).detach().cpu().numpy()\n",
    "\n",
    "# LIME 적용 함수\n",
    "def apply_lime(model, image_path):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model, transform = prepare_model_and_transform(model, device)\n",
    "\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_resized = img.resize((256, 256))\n",
    "    img_tensor = transform(img_resized).unsqueeze(0).to(device)\n",
    "\n",
    "    outputs = model(img_tensor)\n",
    "    probs = torch.softmax(outputs, dim=1).detach().cpu().numpy()[0]\n",
    "    class_idx = np.argmax(probs)\n",
    "    \n",
    "    explainer = lime_image.LimeImageExplainer(random_state=42)\n",
    "    explanation = explainer.explain_instance(np.array(img_resized), lambda x: batch_predict(model, x, transform, device), labels=[class_idx], num_samples=1000)\n",
    "    \n",
    "    temp, mask = explanation.get_image_and_mask(label=class_idx, positive_only=True, num_features=5, hide_rest=False)\n",
    "    img_boundaries = mark_boundaries(temp / 255.0, mask)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(img_boundaries)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('LIME')\n",
    "    \n",
    "    white_image = np.ones_like(temp) * 255\n",
    "    only_important = np.copy(white_image)\n",
    "    only_important[mask != 0] = temp[mask != 0]\n",
    "    \n",
    "    ax[1].imshow(only_important.astype(np.uint8))\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('Important Areas Only')\n",
    "    plt.show()\n",
    "\n",
    "def insertion_deletion(model, img_tensor, mask, mode='insertion', steps=20, class_idx=0):\n",
    "    device = img_tensor.device\n",
    "    img_tensor = img_tensor.clone().detach().to(device)\n",
    "    \n",
    "    scores = []\n",
    "    images = []\n",
    "    step = 1.0 / steps\n",
    "    img_original = img_tensor.clone().detach().cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # 마스크를 (256, 256, 1)로 변환한 후, 3채널로 확장\n",
    "    mask_3d = np.repeat(mask.squeeze().cpu().numpy()[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "    for i in range(steps + 1):\n",
    "        if mode == 'insertion':\n",
    "            # Insertion: 중요 영역을 점차적으로 추가, 나머지 영역을 흰색으로 만듦\n",
    "            modified_img = img_original * (mask_3d * (step * i))\n",
    "        elif mode == 'deletion':\n",
    "            # Deletion: 중요 영역을 점차적으로 제거, 나머지 영역을 흰색으로 만듦\n",
    "            modified_img = img_original * (1 - mask_3d * (step * i))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            modified_tensor = torch.tensor(modified_img).unsqueeze(0).permute(0, 3, 1, 2).to(device)\n",
    "            output = torch.softmax(model(modified_tensor), dim=1)[:, class_idx].cpu().item()\n",
    "        \n",
    "        # 스텝별 출력 추가\n",
    "        print(f'Step {i} - {mode.capitalize()} score: {output}')\n",
    "        \n",
    "        scores.append(output)\n",
    "        images.append(modified_img)\n",
    "\n",
    "    return scores, images\n",
    "\n",
    "# 이미지 정규화 함수\n",
    "def normalize_image(img):\n",
    "    img_min, img_max = img.min(), img.max()\n",
    "    if img_min == img_max:\n",
    "        return img\n",
    "    return (img - img_min) / (img_max - img_min)\n",
    "\n",
    "# Insertion/Deletion 스텝별 시각화 함수\n",
    "def visualize_insertion_deletion_steps(images, mode, steps=20):\n",
    "    fig, axs = plt.subplots(2, (steps // 2) + 1, figsize=(20, 5))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        img = normalize_image(img)\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(f\"{mode.capitalize()} Step {i}\")\n",
    "    \n",
    "    # 남은 빈 플롯들 숨기기\n",
    "    for j in range(len(images), len(axs)):\n",
    "        axs[j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 결과 곡선 시각화\n",
    "def plot_insertion_deletion_curves(insertion_scores, deletion_scores, steps, mode):\n",
    "    plt.plot(range(steps + 1), insertion_scores, label='Insertion', marker='o')\n",
    "    plt.plot(range(steps + 1), deletion_scores, label='Deletion', marker='o')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Model Output Score')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f'Insertion and Deletion Curves ({mode.capitalize()})')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# AUPC 계산 함수\n",
    "def calculate_aupc(scores, steps):\n",
    "    x = np.linspace(0, 1, steps + 1)\n",
    "    return trapz(scores, x)\n",
    "\n",
    "# Insertion 및 Deletion 수행 및 AUPC 계산 적용\n",
    "def apply_insertion_deletion_visualize(model, image_path, cam_mask=None, steps=20, mode='gradcam', class_labels=None):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model, transform = prepare_model_and_transform(model, device)\n",
    "\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_resized = img.resize((256, 256))\n",
    "    img_tensor = transform(img_resized).unsqueeze(0).to(device)\n",
    "\n",
    "    outputs = model(img_tensor)\n",
    "    probs = torch.softmax(outputs, dim=1).detach().cpu().numpy()[0]\n",
    "    class_idx = np.argmax(probs)\n",
    "\n",
    "    if class_labels is not None:\n",
    "        class_name = class_labels[class_idx]\n",
    "        print(f\"Predicted class: {class_name} (class_idx: {class_idx})\")\n",
    "    else:\n",
    "        print(f\"Predicted class_idx: {class_idx}\")\n",
    "\n",
    "    if mode == 'lime':\n",
    "        explainer = lime_image.LimeImageExplainer(random_state=42)\n",
    "        explanation = explainer.explain_instance(np.array(img_resized), lambda x: batch_predict(model, x, transform, device), labels=[class_idx], num_samples=1000)\n",
    "        _, mask = explanation.get_image_and_mask(label=class_idx, positive_only=True, num_features=5, hide_rest=False)\n",
    "        mask = torch.tensor(mask).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "    else:\n",
    "        mask = torch.tensor(cam_mask).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "\n",
    "    # Insertion\n",
    "    print(f'=== Insertion ({mode.capitalize()}) ===')\n",
    "    insertion_scores, insertion_images = insertion_deletion(model, img_tensor, mask, mode='insertion', steps=steps, class_idx=class_idx)\n",
    "    \n",
    "    # Deletion\n",
    "    print(f'=== Deletion ({mode.capitalize()}) ===')\n",
    "    deletion_scores, deletion_images = insertion_deletion(model, img_tensor, mask, mode='deletion', steps=steps, class_idx=class_idx)\n",
    "\n",
    "    # AUPC 계산\n",
    "    insertion_aupc = calculate_aupc(insertion_scores, steps)\n",
    "    deletion_aupc = calculate_aupc(deletion_scores, steps)\n",
    "    total_aupc = (insertion_aupc + deletion_aupc) / 2\n",
    "\n",
    "    print(f'AUPC: {total_aupc:.3f} (insertion: {insertion_aupc:.3f}, deletion: {deletion_aupc:.3f})')\n",
    "\n",
    "    # 결과 곡선 시각화\n",
    "    plot_insertion_deletion_curves(insertion_scores, deletion_scores, steps, mode)\n",
    "\n",
    "    # 스텝별 이미지 시각화\n",
    "    visualize_insertion_deletion_steps(insertion_images, mode='insertion', steps=steps)\n",
    "    visualize_insertion_deletion_steps(deletion_images, mode='deletion', steps=steps)\n",
    "\n",
    "# 실행 예시\n",
    "model_name = 'densenet'\n",
    "image_path = '/home/xai/son/MLRSNet/Images/basketball_court/basketball_court_01327.jpg'\n",
    "\n",
    "class_labels = ['airplane','airport','bare soil','baseball diamond','basketball court','beach','bridge','buildings','cars','chaparral','cloud','containers','crosswalk','dense residential area','desert','dock','factory','field','football field','forest','freeway','golf course','grass','greenhouse','gully','habor','intersection','island','lake','mobile home','mountain','overpass','park','parking lot','parkway','pavement','railway','railway station','river','road','roundabout','runway','sand','sea','ships','snow','snowberg','sparse residential area','stadium','swimming pool','tanks','tennis court','terrace','track','trail','transmission tower','trees','water','wetland','wind turbine']\n",
    "\n",
    "# 모델 로드\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "model = DenseNetModel.load_from_checkpoint(\n",
    "    checkpoint_path='/home/xai/son/src/checkpoints/densenet_final_epoch_20241023_204532.ckpt',\n",
    "    num_classes=config['data']['num_classes'],\n",
    "    learning_rate=config['train']['learning_rate']\n",
    ")\n",
    "# Grad-CAM 수행\n",
    "cam_mask = apply_grad_cam(model, image_path, model_name)\n",
    "\n",
    "step = 10\n",
    "# Insertion 및 Deletion 수행 및 시각화 (Grad-CAM 기반, 클래스 이름 출력)\n",
    "apply_insertion_deletion_visualize(model, image_path, cam_mask=cam_mask, steps=step, mode='gradcam', class_labels=class_labels)\n",
    "\n",
    "# Insertion 및 Deletion 수행 및 시각화 (LIME 기반, 클래스 이름 출력)\n",
    "apply_insertion_deletion_visualize(model, image_path, steps=step, mode='lime', class_labels=class_labels)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
